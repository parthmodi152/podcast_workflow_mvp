# Podcast Workflow MVP

This project is a proof-of-concept workflow that turns a questionnaire (or any long-form content) into a video-podcast featuring multiple AI-cloned speakers. It implements each step as an independent FastAPI micro-service, with a React admin UI for local testing.

## Project Overview

The workflow consists of five microservices that work together to create a video podcast:

1.  **Voice Service**: Clones and catalogs voices using the **ElevenLabs Python SDK**, and stores an associated speaker image locally.
2.  **Script Service**: Generates structured dialogue using OpenAI.
3.  **TTS Service**: Generates audio per line using the **ElevenLabs Python SDK** and saves it locally.
4.  **Avatar Service**: Creates talking-head clips using the **Hedra Python SDK**, utilizing locally stored audio and speaker images. The SDK is used to upload local audio and image files, and then to generate the character video.
5.  **Stitch Service**: Concatenates clips in script order using FFmpeg.

All media is stored locally in mounted volumes, and services communicate via Celery tasks through Redis.

## Project Structure

-   `docker-compose.yml`: Defines all services for local orchestration.
-   `data/`: Directory for local media storage (mounted into services).
    -   `voice-images/`: Speaker images uploaded via the voice service.
    -   `podcast-audio/`: Audio files generated by TTS service.
    -   `podcast-video/`: Video clips generated by avatar service.
    -   `podcast-final/`: Final stitched episodes.
-   `sample_data/`: Example audio and images for testing.
    -   `audio/`: Sample audio files for voice cloning.
    -   `images/`: Sample images for avatar generation.
-   `voice_service/`: FastAPI service for voice cloning using ElevenLabs SDK.
    -   `src/main.py`: API endpoints for voice cloning and listing.
    -   `Dockerfile`: Docker build instructions.
    -   `pyproject.toml`: Python dependencies (includes `elevenlabs`).
-   `script_service/`: FastAPI service for script generation.
    -   `src/main.py`: API endpoints for script creation and status.
    -   `Dockerfile`: Docker build instructions.
    -   `pyproject.toml`: Python dependencies.
-   `tts_service/`: Celery worker for text-to-speech generation using ElevenLabs SDK.
    -   `src/main.py`: Celery tasks for TTS generation.
    -   `Dockerfile`: Docker build instructions.
    -   `pyproject.toml`: Python dependencies (includes `elevenlabs`).
-   `avatar_service/`: Celery worker for avatar video generation using Hedra SDK.
    -   `src/main.py`: Celery tasks for avatar generation.
    -   `Dockerfile`: Docker build instructions.
    -   `pyproject.toml`: Python dependencies (includes `hedra-python`).
-   `stitch_service/`: Celery worker for video stitching.
    -   `src/main.py`: Celery tasks for video stitching.
    -   `Dockerfile`: Docker build instructions.
    -   `pyproject.toml`: Python dependencies.
-   `react_admin_ui/`: React frontend for administration.
    -   `src/App.js`: Main React component.
    -   `Dockerfile`: Docker build instructions.
    -   `package.json`: Node.js dependencies.

## Prerequisites

-   Docker & Docker Compose
-   API keys for:
    -   ElevenLabs (voice cloning and TTS)
    -   OpenAI (script generation)
    -   Hedra (avatar generation)

## Setup and Running Locally

### 1. Clone the repository

```bash
git clone <repository-url>
cd podcast_workflow_mvp
```

### 2. Create a `.env` file with your API keys

Create a `.env` file in the project root with the following content:

```env
ELEVEN_API_KEY=your_elevenlabs_api_key
OPENAI_API_KEY=your_openai_api_key
HEDRA_API_KEY=your_hedra_api_key
```

### 3. Build and start the services

```bash
docker-compose up --build
```

This will start all services:
-   Voice Service: http://localhost:8001
-   Script Service: http://localhost:8002
-   React Admin UI: http://localhost:3000

### 4. Using the React Admin UI

1.  Open http://localhost:3000 in your browser.
2.  Navigate to the "Voices" tab.
3.  Upload a voice with a name, an optional speaker image file (e.g., JPEG, PNG), and audio files.
4.  Navigate to the "Scripts" tab.
5.  Create a new script with a title, length, and select the cloned voices for speakers.
6.  Monitor the script status and view details as it processes through TTS and avatar generation.
7.  When processing is complete, view the final episode in the "Episodes" tab.

## API Usage Examples (cURL)

(Note: cURL examples remain the same as the API interface hasn_t changed, only the internal implementation to use SDKs.)

### Voice Service

#### Clone a voice

```bash
curl -X POST http://localhost:8001/voices \
  -F "name=Host Voice" \
  -F "speaker_image=@/path/to/your/speaker_image.jpg" \
  -F "files=@/path/to/your/sample_audio.mp3"
```

Response:
```json
{
  "voice_id": "cloned_voice_id_from_elevenlabs"
}
```

#### List voices

```bash
curl -X GET http://localhost:8001/voices
```

Response (example):
```json
[
  {
    "id": 1,
    "voice_id": "cloned_voice_id_from_elevenlabs",
    "name": "Host Voice",
    "image_path": "/data/voice-images/timestamp_speaker_image.jpg"
  }
]
```

### Script Service

#### Create a script

```bash
curl -X POST http://localhost:8002/scripts \
  -H "Content-Type: application/json" \
  -d 
{
  "title": "Why LLMs Matter",
  "length_minutes": 5,
  "speakers": [
    {"role": "host", "voice_id": "voice_id_1"},
    {"role": "guest", "voice_id": "voice_id_2"}
  ]
}
```

Response:
```json
{
  "script_id": 1,
  "title": "Why LLMs Matter",
  "status": "processing"
}
```

#### Get script status

```bash
curl -X GET http://localhost:8002/scripts/1
```

Response (example):
```json
{
  "script_id": 1,
  "title": "Why LLMs Matter",
  "status": "processing",
  "length_minutes": 5,
  "lines": [
    {
      "line_id": 1,
      "speaker": "host",
      "text": "Welcome to our podcast on why LLMs matter.",
      "voice_id": "voice_id_1",
      "tts_status": "complete",
      "audio_file_path": "/data/podcast-audio/1_host.mp3",
      "avatar_status": "pending",
      "video_file_path": null
    },
    {
      "line_id": 2,
      "speaker": "guest",
      "text": "Thanks for having me.",
      "voice_id": "voice_id_2",
      "tts_status": "pending",
      "audio_file_path": null,
      "avatar_status": "pending",
      "video_file_path": null
    }
  ]
}
```

## Workflow Process

1.  **Voice Cloning (ElevenLabs SDK)**:
    -   Upload audio samples and an optional speaker image file to clone voices via the Voice Service.
    -   The `voice_service` uses the ElevenLabs Python SDK (`client.voices.add()`) for cloning.
    -   The speaker image is saved locally (e.g., in `/data/voice-images/`).

2.  **Script Generation (OpenAI API)**:
    -   Create a script with title, length, and speakers (using cloned voice IDs).
    -   The Script Service uses OpenAI to generate dialogue.
    -   Each line is assigned to a speaker with their voice ID and the path to their speaker image (retrieved from the VoiceModel).

3.  **Audio Generation (TTS - ElevenLabs SDK)**:
    -   The TTS Service processes each script line.
    -   Audio is generated using the ElevenLabs Python SDK (`client.text_to_speech.convert_as_stream()`) and saved locally (e.g., in `/data/podcast-audio/`).

4.  **Avatar Generation (Hedra SDK)**:
    -   The Avatar Service creates talking-head videos using the Hedra Python SDK.
    -   It uses the locally saved speaker image (if provided) and the locally saved audio file for each line.
    -   The SDK methods `client.audio.create(file=...)` and `client.portraits.create(file=...)` are used to upload local media to Hedra and obtain URLs.
    -   These URLs are then used with `client.characters.create(...)` to generate the video.
    -   The generated video clip is saved locally (e.g., in `/data/podcast-video/`).

5.  **Video Stitching (FFmpeg)**:
    -   The Stitch Service concatenates all video clips for a script in order.
    -   FFmpeg is used to create the final episode.
    -   The completed video is saved locally (e.g., in `/data/podcast-final/`).

## Troubleshooting

-   **Service Connectivity**: Ensure all services are running with `docker-compose ps`.
-   **API Keys**: Verify your API keys are correctly set in the `.env` file.
-   **Logs**: Check service logs with `docker-compose logs <service_name>` (e.g., `docker-compose logs voice_service`).
-   **Storage**: Ensure the `data` directory (and its subdirectories like `voice-images`, `podcast-audio`, etc.) has proper permissions and is correctly mounted by Docker.

## Development Notes

-   All services use Python 3.11, FastAPI, Pydantic, and Poetry.
-   `voice_service` and `tts_service` now use the `elevenlabs` Python SDK.
-   `avatar_service` uses the `hedra-python` SDK for all operations including file uploads.
-   Background jobs are handled by Celery with Redis as the broker.
-   Media (images, audio, video) is stored locally in mounted volumes.
-   The React Admin UI is a minimal implementation for local testing.

## License

[Specify your license here]

